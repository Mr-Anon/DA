{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset has 731 transactions with average 51.926128590971274 items per transaction.\n",
      "\n",
      "MINSUP: 400\n",
      "TIME: 1.0844552516937256 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def prune(item,freq_itemsets):\n",
    "    for i in range(len(item)):\n",
    "        skip = item[:i]+item[i+1:]\n",
    "        if skip not in freq_itemsets:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def aprioriGen(freq_itemsets):\n",
    "    nextCandidates=[]\n",
    "    for i in range(len(freq_itemsets)):\n",
    "        for j in range(i+1,len(freq_itemsets)):\n",
    "            lst = len(freq_itemsets[i])\n",
    "            temp = []\n",
    "            flag = True\n",
    "            for k in range(lst-1):\n",
    "                if freq_itemsets[i][k]==freq_itemsets[j][k]:\n",
    "                    temp.append(freq_itemsets[i][k])\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break\n",
    "            if freq_itemsets[i][-1]>=freq_itemsets[j][-1]:\n",
    "                flag = False\n",
    "            temp = temp + [freq_itemsets[i][-1]] + [freq_itemsets[j][-1]]\n",
    "            if flag and prune(temp, freq_itemsets):\n",
    "                nextCandidates.append(temp)\n",
    "    return nextCandidates\n",
    "\n",
    "\n",
    "def hash_for_2_candidates(transactions, freq_itemsets, minSupport):\n",
    "    \n",
    "    new_items = []\n",
    "    counter = dict()\n",
    "    \n",
    "    for i in transactions:\n",
    "        freq_t = []\n",
    "        for j in i:\n",
    "            if [j] in freq_itemsets:\n",
    "                freq_t.append(j)\n",
    "        for it1 in range(len(freq_t)):\n",
    "            for it2 in range(len(freq_t)):\n",
    "                if freq_t[it2]>freq_t[it1]:\n",
    "                    if (freq_t[it1], freq_t[it2]) not in counter:\n",
    "                        counter[(freq_t[it1], freq_t[it2])]=1\n",
    "                    else:\n",
    "                        counter[(freq_t[it1], freq_t[it2])] = counter[(freq_t[it1], freq_t[it2])] + 1\n",
    "\n",
    "    updated_items = []\n",
    "    \n",
    "    for i in counter:\n",
    "        if counter[i]>=minSupport:\n",
    "            updated_items.append([i[0], i[1]])\n",
    "    \n",
    "    return updated_items\n",
    "    \n",
    "    \n",
    "def update_items(dataset, candidates, minsup):\n",
    "\n",
    "\n",
    "    counter = []\n",
    "    future_transactions = []\n",
    "    for i in range(len(candidates)):\n",
    "        counter.append(0)\n",
    "        future_transactions.append([])\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(candidates)):\n",
    "            if set(candidates[j]) <= set(dataset[i]):\n",
    "                counter[j]+=1\n",
    "                future_transactions[j].append(i)\n",
    "    updated_items = []\n",
    "    for i in range(len(candidates)):\n",
    "        if counter[i]>=minsup:\n",
    "            updated_items.append(candidates[i])\n",
    "    return updated_items\n",
    "\n",
    "def _all_one_itemset(data):\n",
    "    ans = []\n",
    "    for i in data:\n",
    "        ans = ans + i\n",
    "    ans = list(set(ans))\n",
    "    ans = [[i] for i in ans]\n",
    "    return ans\n",
    "\n",
    "def getData(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "    file.close()\n",
    "    data = data.split('-2')\n",
    "    for i in range(len(data)):\n",
    "        data[i] = data[i].split('-1')\n",
    "        data[i] = data[i][:-1]\n",
    "        data[i] = list(map(int, data[i]))\n",
    "    sm=0\n",
    "    for i in data: sm = sm + len(i)\n",
    "    print(f'\\nThe dataset has {len(data)} transactions with average {sm/len(data)} items per transaction.')\n",
    "    return data\n",
    "\n",
    "def update_items_from_partitions(dataset, candidates, minsup, partition_count):\n",
    "    \n",
    "    starting_index = 0\n",
    "    ans = []\n",
    "    minsup = minsup // partition_count\n",
    "    \n",
    "    tt = []\n",
    "    \n",
    "    for i in range(partition_count):\n",
    "        \n",
    "        lst = time.time()\n",
    "        \n",
    "        it1 = starting_index\n",
    "        it2 = starting_index + len(dataset)//partition_count-1\n",
    "        starting_index = it2 + 1\n",
    "        \n",
    "        counter = []\n",
    "        future_transactions = []\n",
    "        \n",
    "        for i in range(len(candidates)):\n",
    "            counter.append(0)\n",
    "            future_transactions.append([])\n",
    "        \n",
    "        for i in range(it1, it2+1):\n",
    "            for j in range(len(candidates)):\n",
    "                if set(candidates[j]) <= set(dataset[i]):\n",
    "                    counter[j]+=1\n",
    "                    future_transactions[j].append(i)\n",
    "                    \n",
    "        updated_items = []\n",
    "\n",
    "        for i in range(len(candidates)):\n",
    "            if counter[i]>=minsup:\n",
    "                updated_items.append(candidates[i])\n",
    "                \n",
    "        tt.append(time.time()-lst)\n",
    "        ans = ans + updated_items\n",
    "        new_ans = []\n",
    "        for elem in ans:\n",
    "            if elem not in new_ans:\n",
    "                new_ans.append(elem)\n",
    "        ans = new_ans.copy()\n",
    "\n",
    "    return ans, max(tt)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    partition_count = 1\n",
    "    dataset = getData('SIGN.txt')\n",
    "    all_one_itemset = _all_one_itemset(dataset)\n",
    "#     _minsup = [600, 550, 500, 450]\n",
    "    _minsup = [400]\n",
    "\n",
    "    for minsup in _minsup:\n",
    "\n",
    "        print(f'\\nMINSUP: {minsup}')\n",
    "\n",
    "        tot_time = 0\n",
    "\n",
    "        frequent_itemset = dict()\n",
    "        lst = time.time()\n",
    "        frequent_itemset[1] = update_items(dataset, all_one_itemset, minsup)\n",
    "        frequent_itemset[2] = hash_for_2_candidates(dataset, frequent_itemset[1], minsup)\n",
    "        tot_time = tot_time + time.time()-lst\n",
    "        candidates = frequent_itemset[2]\n",
    "        \n",
    "        k=2\n",
    "        while candidates:\n",
    "            candidates, tt = update_items_from_partitions(dataset, candidates, minsup, partition_count)\n",
    "            tot_time = tot_time + tt\n",
    "            \n",
    "            lst = time.time()\n",
    "            frequent_itemset[k] = update_items(dataset, candidates, minsup)\n",
    "            candidates = aprioriGen(frequent_itemset[k])\n",
    "            tot_time = tot_time + time.time()-lst\n",
    "            k = k+1\n",
    "        \n",
    "#         for i in frequent_itemset:\n",
    "#             print('NUMBER OF ITEMS: ', i)\n",
    "#             print(frequent_itemset[i])\n",
    "        \n",
    "        print(f'TIME: {tot_time} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "for minsup in _minsup:\n",
    "    start_time = time.time()\n",
    "    gg = apriori(dataset, min_support=minsup/len(dataset))\n",
    "    gg=list(gg)\n",
    "    print(f'MINSUP: {minsup}    TIME: {time.time()-start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpgrowth_py import fpgrowth\n",
    "\n",
    "for minsup in _minsup:\n",
    "    start_time = time.time()\n",
    "    freqItemSet, rules = fpgrowth(dataset, minSupRatio=minsup/len(dataset), minConf=0.0)\n",
    "    print(f'MINSUP: {minsup}    TIME: {time.time()-start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "731\n",
    "5\n",
    "731-5*(731//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg = [1, 2, 3, -5, 5, 6]\n",
    "min(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset has 731 transactions with average 51.926128590971274 items per transaction.\n",
      "\n",
      "MINSUP: 400\n",
      "TIME: 1.1965887546539307 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def prune(item,freq_itemsets):\n",
    "    for i in range(len(item)):\n",
    "        skip = item[:i]+item[i+1:]\n",
    "        if skip not in freq_itemsets:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def aprioriGen(freq_itemsets):\n",
    "    nextCandidates=[]\n",
    "    for i in range(len(freq_itemsets)):\n",
    "        for j in range(i+1,len(freq_itemsets)):\n",
    "            lst = len(freq_itemsets[i])\n",
    "            temp = []\n",
    "            flag = True\n",
    "            for k in range(lst-1):\n",
    "                if freq_itemsets[i][k]==freq_itemsets[j][k]:\n",
    "                    temp.append(freq_itemsets[i][k])\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break\n",
    "            if freq_itemsets[i][-1]>=freq_itemsets[j][-1]:\n",
    "                flag = False\n",
    "            temp = temp + [freq_itemsets[i][-1]] + [freq_itemsets[j][-1]]\n",
    "            if flag and prune(temp, freq_itemsets):\n",
    "                nextCandidates.append(temp)\n",
    "    return nextCandidates\n",
    "\n",
    "\n",
    "def hash_for_2_candidates(transactions, freq_itemsets, minSupport):\n",
    "    \n",
    "    new_items = []\n",
    "    counter = dict()\n",
    "    \n",
    "    for i in transactions:\n",
    "        freq_t = []\n",
    "        for j in i:\n",
    "            if [j] in freq_itemsets:\n",
    "                freq_t.append(j)\n",
    "        for it1 in range(len(freq_t)):\n",
    "            for it2 in range(len(freq_t)):\n",
    "                if freq_t[it2]>freq_t[it1]:\n",
    "                    if (freq_t[it1], freq_t[it2]) not in counter:\n",
    "                        counter[(freq_t[it1], freq_t[it2])]=1\n",
    "                    else:\n",
    "                        counter[(freq_t[it1], freq_t[it2])] = counter[(freq_t[it1], freq_t[it2])] + 1\n",
    "\n",
    "    updated_items = []\n",
    "    \n",
    "    for i in counter:\n",
    "        if counter[i]>=minSupport:\n",
    "            updated_items.append([i[0], i[1]])\n",
    "    \n",
    "    return updated_items\n",
    "    \n",
    "    \n",
    "def update_items(dataset, candidates, minsup):\n",
    "\n",
    "\n",
    "    counter = []\n",
    "    future_transactions = []\n",
    "    for i in range(len(candidates)):\n",
    "        counter.append(0)\n",
    "        future_transactions.append([])\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(candidates)):\n",
    "            if set(candidates[j]) <= set(dataset[i]):\n",
    "                counter[j]+=1\n",
    "                future_transactions[j].append(i)\n",
    "    updated_items = []\n",
    "    for i in range(len(candidates)):\n",
    "        if counter[i]>=minsup:\n",
    "            updated_items.append(candidates[i])\n",
    "    return updated_items\n",
    "\n",
    "def _all_one_itemset(data):\n",
    "    ans = []\n",
    "    for i in data:\n",
    "        ans = ans + i\n",
    "    ans = list(set(ans))\n",
    "    ans = [[i] for i in ans]\n",
    "    return ans\n",
    "\n",
    "def getData(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "    file.close()\n",
    "    data = data.split('-2')\n",
    "    for i in range(len(data)):\n",
    "        data[i] = data[i].split('-1')\n",
    "        data[i] = data[i][:-1]\n",
    "        data[i] = list(map(int, data[i]))\n",
    "    sm=0\n",
    "    for i in data: sm = sm + len(i)\n",
    "    print(f'\\nThe dataset has {len(data)} transactions with average {sm/len(data)} items per transaction.')\n",
    "    return data\n",
    "\n",
    "def update_items_from_partitions(dataset, candidates, minsup, partition_count):\n",
    "    \n",
    "    starting_index = 0\n",
    "    ans = []\n",
    "    minsup = minsup // partition_count\n",
    "    \n",
    "    tt = []\n",
    "    \n",
    "    for i in range(partition_count):\n",
    "        \n",
    "        lst = time.time()\n",
    "        \n",
    "        it1 = starting_index\n",
    "        it2 = starting_index + len(dataset)//partition_count-1\n",
    "        starting_index = it2 + 1\n",
    "        \n",
    "        counter = []\n",
    "        future_transactions = []\n",
    "        \n",
    "        for i in range(len(candidates)):\n",
    "            counter.append(0)\n",
    "            future_transactions.append([])\n",
    "        \n",
    "        for i in range(it1, it2+1):\n",
    "            for j in range(len(candidates)):\n",
    "                if set(candidates[j]) <= set(dataset[i]):\n",
    "                    counter[j]+=1\n",
    "                    future_transactions[j].append(i)\n",
    "                    \n",
    "        updated_items = []\n",
    "\n",
    "        for i in range(len(candidates)):\n",
    "            if counter[i]>=minsup:\n",
    "                updated_items.append(candidates[i])\n",
    "                \n",
    "        tt.append(time.time()-lst)\n",
    "        ans = ans + updated_items\n",
    "        new_ans = []\n",
    "        for elem in ans:\n",
    "            if elem not in new_ans:\n",
    "                new_ans.append(elem)\n",
    "        ans = new_ans.copy()\n",
    "\n",
    "    return ans, max(tt)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    partition_count = 1\n",
    "    dataset = getData('SIGN.txt')\n",
    "    all_one_itemset = _all_one_itemset(dataset)\n",
    "#     _minsup = [600, 550, 500, 450]\n",
    "    _minsup = [400]\n",
    "\n",
    "    for minsup in _minsup:\n",
    "\n",
    "        print(f'\\nMINSUP: {minsup}')\n",
    "\n",
    "        tot_time = 0\n",
    "\n",
    "        frequent_itemset = dict()\n",
    "        lst = time.time()\n",
    "        frequent_itemset[1] = update_items(dataset, all_one_itemset, minsup)\n",
    "        frequent_itemset[2] = hash_for_2_candidates(dataset, frequent_itemset[1], minsup)\n",
    "        tot_time = tot_time + time.time()-lst\n",
    "        candidates = frequent_itemset[2]\n",
    "        \n",
    "        k=2\n",
    "        while candidates:\n",
    "            candidates, tt = update_items_from_partitions(dataset, candidates, minsup, partition_count)\n",
    "            tot_time = tot_time + tt\n",
    "            \n",
    "            lst = time.time()\n",
    "            frequent_itemset[k] = update_items(dataset, candidates, minsup)\n",
    "            candidates = aprioriGen(frequent_itemset[k])\n",
    "            tot_time = tot_time + time.time()-lst\n",
    "            k = k+1\n",
    "        \n",
    "#         for i in frequent_itemset:\n",
    "#             print('NUMBER OF ITEMS: ', i)\n",
    "#             print(frequent_itemset[i])\n",
    "        \n",
    "        print(f'TIME: {tot_time} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
